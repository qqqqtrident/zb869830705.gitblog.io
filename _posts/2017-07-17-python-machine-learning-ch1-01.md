---
layout: post
author: Robin
title: Python机器学习Ch1-01 --- 让计算机从数据中学习
tags: 机器学习, Python
categories:
  - 机器学习 
  - Python
---

我个人认为，机器学习（machine learning）是计算机领域中迄今为止最令人振奋的方向！我们生活在一个数据大爆炸的时代，通过运用各种机器学习领域中的自学习算法，我们可以将数据转化为知识。也感谢近年来这一领域中开源软件的风波发展，这真是一个美好的时代。

这一章，我们将学习机器学习中的一些重要的概念和几类常用的算法。最主要的是可以借助Python和开源机器学习库来解决一些实际的问题。

主要的主题包括：

* 机器学习的一些概念
* 三类机器学习算法
* 如何设计一个成熟的机器学习系统
* 安装Python

## 建立智能机器将数据转化为知识

如今，我们最不缺的就是数据：不论是结构化的还是非结构化的数据。在20世纪下叶，机器学习作为人工智能（artificial intelligence）的子领域诞生了，它的主要目标是通过自学习算法从数据中获取知识，然后对未来世界进行预测。无需借助人力从庞大的数据中得到规则，机器学习能够自己建立规则模型，并对未知进行预测。机器学习不但在计算机学习中变的越发重要，还在我们的日常生活中发挥了很大的作用。有了机器学习，我们才能享受垃圾邮件的过滤技术、文字和语音的识别技术、可信赖的网页搜索技术以及现在很火的自动驾驶技术等。


## 三类机器学习算法

在此部分，我们将看看机器学习的三类学习算法：监督学习（supervised learning）、无监督学习（unsupervised learning）、强化学习（reinforcement learning）。我们将使用概念性的例子来了解三种不同的学习算法之间的根本区别，我们将开发一个直觉的领域可以应用这些实际问题:

![](/assets/three-types-machine-learning.png)

### 使用监督学习对未来进行预测

**监督学习**的目标是从标签数据中学习得到模型，并对未知或者未来的数据进行预测。这里的**监督**是指针对样本集的输出信号（标签）是已知的。

比如我们拿垃圾邮件过滤来说，我们可以使用已经被标记为**垃圾邮件**和**非垃圾邮件**的数据样本集，使用机器学习监督学习算法训练得到一个模型，来预测未来的某封邮件是否为垃圾邮件。这里的分类输出信号有两个：**垃圾邮件**和**非垃圾邮件**，我们可以假设**垃圾邮件**的输出信号为**1**，**非垃圾邮件**的输出信号为**0**，这样机器学习算法模型的输出信号共有两个：**0**和**1**，其输出是非连续的，离散的值，这是一个典型的机器学习**二分类**的问题，也是一个机器学习**分类**问题。机器学习还有一个子类就是**回归**，**回归**问题的输出是一个连续的值。

![](/assets/supervised-learning-flow.jpg)

### 分类 --- 离散预测结果

**分类**是机器学习的一个子类，其目标是通过对标签数据的学习，得到一个分类模型，并对未知或者未来的数据进行分类的方法。其中**标签是离散的，无序的**，可以理解标签就是一组数据的关系类别。之前的垃圾邮件分类问题是一个二分类的问题，机器学习通过对标签数据，也就是被标记为垃圾邮件和非垃圾邮件的数据集进行学习，得到一个二分类模型，并在未来对新的邮件进行分类的问题。

但是标签数据不仅仅只有两个类别，机器学习分类方法也可以对多个类别标签数据进行分类。例如手写数字识别问题，机器学习算法可以对10种类型进行分类，首先收集10种类型数字的手写稿件，并且每一种类型的数字都已经被标记。机器学习算法通过对这些标签数据进行学习后，得到一个10分类的模型，当用户输入新的手写数字后，模型根据历史经验对数字进行识别判断，最终给出手写数组对应的阿拉伯数字。

下图是一个典型二分类问题的示意图。假设我们有30个训练样本数据：15个样本数据为负样本（用圈表示），15个样本数据为正样本（用加号表示）。在这个场景中，我们的数据是二维的，这意味着每个样本都有与之关联的两个值：\\(x_1\\)和\\(x_2\\)。现在我们可以使用机器学习监督学习算法来学习一个规则 --- 分类边界表示为图中的黑色虚线，它可以分类两个类别的数据以及新的数据落入哪个类的问题。

![](/assets/supervised-learning-classification-binary-classes.jpg)

### 回归 --- 连续预测结果

上面我们学习了分类问题，其输出结果是离散的、无序的。机器学习的第二个子类是**回归**，回归针对的是连续的输出结果问题，回归又叫做**回归分析**。在回归分析中，有许多的预测（解释）变量和联系的反应变量（结果），我们试图找到这些变量之间的关系，使得我们能够预测其最终的输出结果。例如我们有兴趣预测学生的数学成绩，假如最终的成绩和平时学生所花时间有一定的关系的话，我们就能够使用这些历史数据训练得到一个模型，这个模型能够针对学生平时所花的时间来预测最终的考试成绩。

下图说明了线性回归的概念。给定一个预测变量*x*和一个响应变量*y*，我们对这些数据点进行拟合，最终绘制一条直线，使得各个点和直线间的距离最小 --- 最常见的是平均距离 --- 对于采样点和拟合线之间。现在我们就可以使用从这些数据中学习到的直线的截距和斜率来预测新数据的结果变量：

![](/assets/linear-regression.jpg)

### 解决与强化学习的互动问题

另一种机器学习类型是**强化学习**。在强化学习中，目标是开发一种基于环境交互来改善其性能的系统。由于关于当前环境状况的信息通常包括所谓的*奖励信号*，所以我们可以将强化学习看作是与监督学习相关的领域。然而，在强化学习中，这种反馈不是正确的或者真实的标签，而是衡量一个奖励功能对行动的衡量程度。通过与环境的互动，系统可以使用强化学习来学习一系列的行动，通过探索性的试错法或者审议计划来最大化这种奖励。

强化学习一个比较流行的例子是象棋引擎。在这里，系统根据棋盘的状态（环境）决定一系列的动作，奖励可以在游戏结束时被定义为赢或者输：

![](/assets/reinforcement-learning.jpg)

### 使用无监督学习发现隐藏的结构

在监督学习中，我们知道在训练模型前，正确的输出标签是已知的，以及在强化学习中，每个系列的行为已经被设定了奖励衡量标准，但是在无监督学习中，我们面对而是无标签的数据或者未知结构的数据。使用无监督学习技术，我们可以窥探数据中的结构，以及提取数据中有意义的信息，而无需知道结果变量或者奖励的标准。

### 使用聚类找到数据子集

**聚类**是一种探索性的数据分析技术，可以让我们将一堆信息组织成有意义的子集（集群），而不需要对组织成员有过多的认知知识。在分析期间可能出现每个集群定义了一组共享的、具有一定程度相似性的对象，但是集群之间中的对象却不相似，这就是为什么聚类有时候被成为“无监督学习分类”。聚类是构建信息和数据之间有意义的关系的一种很好的技术，例如，营销人员可以根据客户的兴趣爱好发现客户群，以便进行不同的营销活动。

下图说明了如何将聚类应用于基于特征\\(x_1\\)和\\(x_2\\)的相似性，将未标记的数据组织成三个不同的集群中：

![](/assets/clustering.jpg)

### 数据压缩中的降维

无监督学习的另一个子领域是**降维**。通常，我们正在处理高维度的数据，每次观察都有大量的观察结果，这对于有限的存储空间和机器学习算法的计算性能来说都是一个挑战。无监督降维是特征处理过程中，从数据中去除噪声的常用方法，也可能降低某些算法的预测性能，并将数据压缩到较小的尺寸上，同时保留大部分的相关信息的技术。

有时，维度降低对于可视化也是有用的，例如，高维的特征集可以投影到一维、二维或者三维上，以便通过3D或者2D散点图进行可视化等。 下图显示了一个例子，其中应用非线性维数降低来将3D瑞士卷图压缩到新的2D特征子空间：

![](/assets/dimensionality-reduction-eg.jpg)


> 文章内容来自《Python Machine Learning》
> 
> 由于正在学习，因此在记录过程中难免有误，请不吝指正批评，谢谢！


